import os
import io
import docx
import PyPDF2
import re
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter
from tkinter import Tk, filedialog, messagebox, ttk, Text, END, WORD
import tkinter as tk
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
from wordcloud import WordCloud

class ResumeAnalyzer:
    def __init__(self):
        self.resume_text = ""
        self.job_desc_text = ""
        self.resume_keywords = []
        self.common_phrases = []
        self.matching_keywords = []
        self.missing_keywords = []
        
    # === Text Extraction ===
    
    def extract_text_from_pdf(self, file_path):
        """Extract text from PDF files"""
        text = ""
        try:
            with open(file_path, "rb") as f:
                pdf_reader = PyPDF2.PdfReader(f)
                for page in pdf_reader.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
        except Exception as e:
            print(f"Error extracting PDF text: {e}")
        return text

    def extract_text_from_docx(self, file_path):
        """Extract text from DOCX files"""
        text = ""
        try:
            doc = docx.Document(file_path)
            for para in doc.paragraphs:
                text += para.text + "\n"
            # Also extract text from tables
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        text += cell.text + "\n"
        except Exception as e:
            print(f"Error extracting DOCX text: {e}")
        return text

    def extract_text(self, file_path):
        """Extract text based on file extension"""
        if file_path.lower().endswith(".pdf"):
            return self.extract_text_from_pdf(file_path)
        elif file_path.lower().endswith(".docx"):
            return self.extract_text_from_docx(file_path)
        elif file_path.lower().endswith(".txt"):
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        else:
            raise ValueError("Unsupported file format. Use PDF, DOCX, or TXT.")

    # === Text Processing ===
    
    def clean_and_tokenize(self, text):
        """Clean and tokenize text into individual words"""
        text = re.sub(r'[^a-zA-Z\s]', ' ', text)
        words = text.lower().split()
        # Extended stop words list
        stop_words = set([
            "a", "an", "the", "and", "or", "for", "in", "on", "at", "to", "of", "with", "is", "are", "i", "you", "he", "she", "it", 
            "we", "they", "them", "this", "that", "these", "those", "have", "has", "had", "as", "by", "be", "was", "were", "will",
            "would", "can", "could", "should", "from", "my", "your", "their", "but", "not", "if", "than", "so", "then", "all", "any",
            "no", "just", "do", "does", "did", "about", "above", "after", "again", "against", "am", "because", "been", "before", 
            "being", "below", "between", "both", "each", "few", "further", "here", "how", "into", "more", "most", "other", "own", 
            "same", "some", "such", "too", "very", "which", "who", "whom", "why", "also", "up", "down", "out", "over", "under",
            "through", "during", "before", "after", "while", "since", "until", "when", "where", "why", "how"
        ])
        return [word for word in words if word not in stop_words and len(word) > 2]

    def extract_phrases(self, text, min_length=2, max_length=3):
        """Extract common phrases (n-grams) from text"""
        text = re.sub(r'[^a-zA-Z\s]', ' ', text.lower())
        words = text.split()
        
        # Remove stop words from the words list
        stop_words = set([
            "a", "an", "the", "and", "or", "for", "in", "on", "at", "to", "of", "with", "is", "are", "i", "you", "he", "she", "it", 
            "we", "they", "them", "this", "that", "these", "those", "have", "has", "had", "as", "by", "be", "was", "were", "will",
            "would", "can", "could", "should", "from", "my", "your", "their", "but", "not", "if", "than", "so", "then"
        ])
        filtered_words = [word for word in words if word not in stop_words and len(word) > 2]
        
        # Extract n-grams
        phrases = []
        for n in range(min_length, max_length + 1):
            for i in range(len(filtered_words) - n + 1):
                phrase = ' '.join(filtered_words[i:i+n])
                phrases.append(phrase)
        
        # Count phrase occurrences
        phrase_counter = Counter(phrases)
        return phrase_counter.most_common(15)  # Return top 15 phrases

    # === Keyword Analysis ===
    
    def extract_keywords_tfidf(self, text, top_n=25):
        """Extract keywords using TF-IDF"""
        # Use TF-IDF to identify important words
        tfidf_vectorizer = TfidfVectorizer(
            stop_words='english',
            ngram_range=(1, 2),  # Consider both unigrams and bigrams
            max_df=0.85,         # Ignore terms that appear in >85% of documents
            min_df=2             # Ignore terms that appear in <2 documents
        )
        
        # Create a small corpus by splitting text into paragraphs
        paragraphs = [p for p in text.split('\n') if p.strip()]
        if len(paragraphs) < 3:  # If not enough paragraphs, create some
            paragraphs = [text[i:i+500] for i in range(0, len(text), 500)]
        
        # Calculate TF-IDF
        try:
            tfidf_matrix = tfidf_vectorizer.fit_transform(paragraphs)
            feature_names = tfidf_vectorizer.get_feature_names_out()
            
            # Sum TF-IDF scores across all paragraphs
            tfidf_sums = np.sum(tfidf_matrix.toarray(), axis=0)
            
            # Create dict of term:score
            tfidf_scores = {feature_names[i]: tfidf_sums[i] for i in range(len(feature_names))}
            
            # Sort by score
            sorted_keywords = sorted(tfidf_scores.items(), key=lambda x: x[1], reverse=True)
            return sorted_keywords[:top_n]
        except Exception as e:
            # Fallback to basic keyword extraction if TF-IDF fails
            print(f"TF-IDF failed: {e}, falling back to basic extraction")
            return self.extract_keywords_basic(text, top_n)
            
    def extract_keywords_basic(self, text, top_n=25):
        """Basic keyword extraction using frequency"""
        tokens = self.clean_and_tokenize(text)
        counter = Counter(tokens)
        return counter.most_common(top_n)
    
    # === Job Matching ===
    
    def match_with_job_description(self, resume_text, job_desc_text):
        """Find matching and missing keywords between resume and job description"""
        # Extract keywords from both documents
        job_tokens = set(self.clean_and_tokenize(job_desc_text))
        resume_tokens = set(self.clean_and_tokenize(resume_text))
        
        # Find matching and missing keywords
        matching = job_tokens.intersection(resume_tokens)
        missing = job_tokens - resume_tokens
        
        # Sort by importance (using frequency in job description)
        job_token_freq = Counter(self.clean_and_tokenize(job_desc_text))
        
        matching_kw = [(word, job_token_freq[word]) for word in matching]
        missing_kw = [(word, job_token_freq[word]) for word in missing]
        
        # Sort by frequency
        matching_kw.sort(key=lambda x: x[1], reverse=True)
        missing_kw.sort(key=lambda x: x[1], reverse=True)
        
        return matching_kw[:20], missing_kw[:20]  # Return top 20 for each
        
    # === Visualization ===
    
    def generate_wordcloud(self, text, title):
        """Generate a word cloud from text"""
        # Clean text
        clean_text = ' '.join(self.clean_and_tokenize(text))
        
        # Create and configure the word cloud
        wordcloud = WordCloud(
            width=800, 
            height=400, 
            background_color='white',
            colormap='viridis',
            max_words=100
        ).generate(clean_text)
        
        # Create a figure
        plt.figure(figsize=(10, 5))
        plt.imshow(wordcloud, interpolation='bilinear')
        plt.axis("off")
        plt.title(title)
        
        # Save to a temporary file and return the filename
        filename = "wordcloud.png"
        plt.savefig(filename, bbox_inches='tight')
        plt.close()
        return filename
    
    def generate_match_chart(self, matching, missing):
        """Generate a chart showing matching vs missing keywords"""
        # Count matching and missing
        match_count = len(matching)
        miss_count = len(missing)
        total = match_count + miss_count
        
        # Create data
        labels = ['Matching', 'Missing']
        sizes = [match_count, miss_count]
        colors = ['#5cb85c', '#d9534f']
        
        # Create chart
        plt.figure(figsize=(6, 4))
        plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)
        plt.axis('equal')
        plt.title('Resume-Job Description Match Analysis')
        
        # Save to a temporary file and return the filename
        filename = "match_chart.png"
        plt.savefig(filename, bbox_inches='tight')
        plt.close()
        return filename

    # === Main Analysis ===
    
    def analyze_resume(self, file_path):
        """Analyze resume and extract keywords"""
        self.resume_text = self.extract_text(file_path)
        self.resume_keywords = self.extract_keywords_tfidf(self.resume_text)
        self.common_phrases = self.extract_phrases(self.resume_text)
        return self.resume_text, self.resume_keywords, self.common_phrases
    
    def analyze_job_description(self, file_path):
        """Analyze job description file"""
        self.job_desc_text = self.extract_text(file_path)
        return self.job_desc_text
        
    def compare_resume_with_job(self):
        """Compare resume with job description"""
        if not self.resume_text or not self.job_desc_text:
            return [], []
        
        self.matching_keywords, self.missing_keywords = self.match_with_job_description(
            self.resume_text, self.job_desc_text
        )
        return self.matching_keywords, self.missing_keywords


class ResumeAnalyzerGUI:
    def __init__(self, root):
        self.root = root
        self.root.title("Advanced Resume Keyword Analyzer")
        self.root.geometry("950x700")
        self.root.minsize(950, 700)
        
        self.analyzer = ResumeAnalyzer()
        self.setup_ui()
        
    def setup_ui(self):
        """Set up the user interface"""
        # Create notebook (tabs)
        self.notebook = ttk.Notebook(self.root)
        self.notebook.pack(fill="both", expand=True, padx=10, pady=10)
        
        # Tab 1: Resume Analysis
        self.resume_tab = ttk.Frame(self.notebook)
        self.notebook.add(self.resume_tab, text="Resume Analysis")
        self.setup_resume_tab()
        
        # Tab 2: Job Matching
        self.job_tab = ttk.Frame(self.notebook)
        self.notebook.add(self.job_tab, text="Job Matching")
        self.setup_job_tab()
        
        # Status bar at bottom
        self.status_var = tk.StringVar()
        self.status_var.set("Ready")
        self.status_bar = ttk.Label(self.root, textvariable=self.status_var, relief="sunken", anchor="w")
        self.status_bar.pack(side="bottom", fill="x")
        
    def setup_resume_tab(self):
        """Set up the resume analysis tab"""
        # Frame for file selection
        file_frame = ttk.LabelFrame(self.resume_tab, text="Resume File")
        file_frame.pack(fill="x", padx=10, pady=10)
        
        self.resume_path_var = tk.StringVar()
        ttk.Entry(file_frame, textvariable=self.resume_path_var, width=70).pack(side="left", padx=5, pady=5, expand=True, fill="x")
        ttk.Button(file_frame, text="Browse...", command=self.browse_resume).pack(side="left", padx=5, pady=5)
        ttk.Button(file_frame, text="Analyze", command=self.analyze_resume).pack(side="left", padx=5, pady=5)
        
        # Frame for results
        results_frame = ttk.Frame(self.resume_tab)
        results_frame.pack(fill="both", expand=True, padx=10, pady=10)
        
        # Left panel - Keywords
        left_panel = ttk.LabelFrame(results_frame, text="Keywords & Phrases")
        left_panel.pack(side="left", fill="both", expand=True, padx=5, pady=5)
        
        # Keywords section
        keywords_frame = ttk.LabelFrame(left_panel, text="Important Keywords (with TF-IDF score)")
        keywords_frame.pack(fill="both", expand=True, padx=5, pady=5)
        
        self.keywords_text = Text(keywords_frame, wrap=WORD, width=30, height=15)
        self.keywords_text.pack(fill="both", expand=True, padx=5, pady=5)
        keywords_scrollbar = ttk.Scrollbar(self.keywords_text, command=self.keywords_text.yview)
        self.keywords_text.configure(yscrollcommand=keywords_scrollbar.set)
        keywords_scrollbar.pack(side="right", fill="y")
        
        # Phrases section
        phrases_frame = ttk.LabelFrame(left_panel, text="Common Phrases")
        phrases_frame.pack(fill="both", expand=True, padx=5, pady=5)
        
        self.phrases_text = Text(phrases_frame, wrap=WORD, width=30, height=10)
        self.phrases_text.pack(fill="both", expand=True, padx=5, pady=5)
        phrases_scrollbar = ttk.Scrollbar(self.phrases_text, command=self.phrases_text.yview)
        self.phrases_text.configure(yscrollcommand=phrases_scrollbar.set)
        phrases_scrollbar.pack(side="right", fill="y")
        
        # Right panel - Preview
        right_panel = ttk.LabelFrame(results_frame, text="Resume Preview")
        right_panel.pack(side="right", fill="both", expand=True, padx=5, pady=5)
        
        self.preview_text = Text(right_panel, wrap=WORD)
        self.preview_text.pack(fill="both", expand=True, padx=5, pady=5)
        preview_scrollbar = ttk.Scrollbar(self.preview_text, command=self.preview_text.yview)
        self.preview_text.configure(yscrollcommand=preview_scrollbar.set)
        preview_scrollbar.pack(side="right", fill="y")
        
        # Export button
        ttk.Button(self.resume_tab, text="Export Results", command=self.export_resume_results).pack(pady=10)
        
    def setup_job_tab(self):
        """Set up the job matching tab"""
        # Frame for file selection
        files_frame = ttk.LabelFrame(self.job_tab, text="Files")
        files_frame.pack(fill="x", padx=10, pady=10)
        
        # Resume file selection
        resume_frame = ttk.Frame(files_frame)
        resume_frame.pack(fill="x", padx=5, pady=5)
        ttk.Label(resume_frame, text="Resume:").pack(side="left", padx=5)
        self.job_resume_path_var = tk.StringVar()
        ttk.Entry(resume_frame, textvariable=self.job_resume_path_var, width=50).pack(side="left", padx=5, expand=True, fill="x")
        ttk.Button(resume_frame, text="Browse...", command=self.browse_job_resume).pack(side="left", padx=5)
        
        # Job description file selection
        job_frame = ttk.Frame(files_frame)
        job_frame.pack(fill="x", padx=5, pady=5)
        ttk.Label(job_frame, text="Job Description:").pack(side="left", padx=5)
        self.job_desc_path_var = tk.StringVar()
        ttk.Entry(job_frame, textvariable=self.job_desc_path_var, width=50).pack(side="left", padx=5, expand=True, fill="x")
        ttk.Button(job_frame, text="Browse...", command=self.browse_job_desc).pack(side="left", padx=5)
        
        # Analyze button
        ttk.Button(files_frame, text="Compare Resume with Job", command=self.compare_resume_job).pack(pady=10)
        
        # Results frame
        results_frame = ttk.Frame(self.job_tab)
        results_frame.pack(fill="both", expand=True, padx=10, pady=10)
        
        # Left panel - Matching keywords
        left_panel = ttk.LabelFrame(results_frame, text="Matching Keywords")
        left_panel.pack(side="left", fill="both", expand=True, padx=5, pady=5)
        
        self.matching_text = Text(left_panel, wrap=WORD, width=40, height=20)
        self.matching_text.pack(fill="both", expand=True, padx=5, pady=5)
        matching_scrollbar = ttk.Scrollbar(self.matching_text, command=self.matching_text.yview)
        self.matching_text.configure(yscrollcommand=matching_scrollbar.set)
        matching_scrollbar.pack(side="right", fill="y")
        
        # Right panel - Missing keywords
        right_panel = ttk.LabelFrame(results_frame, text="Missing Keywords")
        right_panel.pack(side="right", fill="both", expand=True, padx=5, pady=5)
        
        self.missing_text = Text(right_panel, wrap=WORD, width=40, height=20)
        self.missing_text.pack(fill="both", expand=True, padx=5, pady=5)
        missing_scrollbar = ttk.Scrollbar(self.missing_text, command=self.missing_text.yview)
        self.missing_text.configure(yscrollcommand=missing_scrollbar.set)
        missing_scrollbar.pack(side="right", fill="y")
        
        # Match percentage
        self.match_var = tk.StringVar()
        self.match_var.set("Match percentage: N/A")
        ttk.Label(self.job_tab, textvariable=self.match_var, font=("Arial", 12, "bold")).pack(pady=5)
        
        # Export button
        ttk.Button(self.job_tab, text="Export Comparison Results", command=self.export_job_results).pack(pady=10)
        
    # === Event handlers ===
    
    def browse_resume(self):
        """Open file dialog to select resume"""
        file_path = filedialog.askopenfilename(
            title="Select Resume File",
            filetypes=[("Documents", "*.pdf;*.docx;*.txt"), ("PDF files", "*.pdf"), 
                      ("Word Documents", "*.docx"), ("Text files", "*.txt")]
        )
        if file_path:
            self.resume_path_var.set(file_path)
            
    def browse_job_resume(self):
        """Open file dialog to select resume for job matching"""
        file_path = filedialog.askopenfilename(
            title="Select Resume File",
            filetypes=[("Documents", "*.pdf;*.docx;*.txt"), ("PDF files", "*.pdf"), 
                      ("Word Documents", "*.docx"), ("Text files", "*.txt")]
        )
        if file_path:
            self.job_resume_path_var.set(file_path)
            self.resume_path_var.set(file_path)  # Also update in the first tab
            
    def browse_job_desc(self):
        """Open file dialog to select job description"""
        file_path = filedialog.askopenfilename(
            title="Select Job Description File",
            filetypes=[("Documents", "*.pdf;*.docx;*.txt"), ("PDF files", "*.pdf"), 
                      ("Word Documents", "*.docx"), ("Text files", "*.txt")]
        )
        if file_path:
            self.job_desc_path_var.set(file_path)
            
    def analyze_resume(self):
        """Analyze the selected resume"""
        file_path = self.resume_path_var.get()
        if not file_path:
            messagebox.showwarning("Warning", "Please select a resume file first.")
            return
            
        try:
            self.status_var.set("Analyzing resume...")
            self.root.update_idletasks()
            
            # Analyze resume
            resume_text, keywords, phrases = self.analyzer.analyze_resume(file_path)
            
            # Update UI with results
            self.preview_text.delete(1.0, END)
            self.preview_text.insert(END, resume_text[:5000] + ("..." if len(resume_text) > 5000 else ""))
            
            self.keywords_text.delete(1.0, END)
            for keyword, score in keywords:
                self.keywords_text.insert(END, f"{keyword}: {score:.4f}\n")
                
            self.phrases_text.delete(1.0, END)
            for phrase, count in phrases:
                self.phrases_text.insert(END, f"{phrase}: {count}\n")
                
            self.status_var.set(f"Analysis complete. Found {len(keywords)} keywords and {len(phrases)} common phrases.")
            
        except Exception as e:
            messagebox.showerror("Error", f"An error occurred: {str(e)}")
            self.status_var.set("Analysis failed.")
            
    def compare_resume_job(self):
        """Compare resume with job description"""
        resume_path = self.job_resume_path_var.get()
        job_path = self.job_desc_path_var.get()
        
        if not resume_path or not job_path:
            messagebox.showwarning("Warning", "Please select both resume and job description files.")
            return
            
        try:
            self.status_var.set("Comparing resume with job description...")
            self.root.update_idletasks()
            
            # Analyze resume if needed
            if not self.analyzer.resume_text or resume_path != self.resume_path_var.get():
                self.analyzer.analyze_resume(resume_path)
                self.resume_path_var.set(resume_path)  # Update in the first tab
                
            # Analyze job description
            self.analyzer.analyze_job_description(job_path)
            
            # Compare
            matching, missing = self.analyzer.compare_resume_with_job()
            
            # Update UI
            self.matching_text.delete(1.0, END)
            for word, count in matching:
                self.matching_text.insert(END, f"{word}: {count}\n")
                
            self.missing_text.delete(1.0, END)
            for word, count in missing:
                self.missing_text.insert(END, f"{word}: {count}\n")
                
            # Calculate and display match percentage
            if matching or missing:
                match_pct = len(matching) / (len(matching) + len(missing)) * 100
                self.match_var.set(f"Match percentage: {match_pct:.1f}%")
            else:
                self.match_var.set("Match percentage: N/A")
                
            self.status_var.set(f"Comparison complete. Found {len(matching)} matching keywords and {len(missing)} missing keywords.")
            
        except Exception as e:
            messagebox.showerror("Error", f"An error occurred: {str(e)}")
            self.status_var.set("Comparison failed.")
            
    def export_resume_results(self):
        """Export resume analysis results to a file"""
        if not self.analyzer.resume_text:
            messagebox.showwarning("Warning", "No resume has been analyzed yet.")
            return
            
        file_path = filedialog.asksaveasfilename(
            title="Save Analysis Results",
            defaultextension=".txt",
            filetypes=[("Text files", "*.txt"), ("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if not file_path:
            return
            
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write("RESUME KEYWORD ANALYSIS RESULTS\n")
                f.write("===============================\n\n")
                
                f.write("IMPORTANT KEYWORDS (TF-IDF SCORE)\n")
                f.write("--------------------------------\n")
                for keyword, score in self.analyzer.resume_keywords:
                    f.write(f"{keyword}: {score:.4f}\n")
                f.write("\n")
                
                f.write("COMMON PHRASES\n")
                f.write("-------------\n")
                for phrase, count in self.analyzer.common_phrases:
                    f.write(f"{phrase}: {count}\n")
                f.write("\n")
                
                f.write("RESUME TEXT PREVIEW\n")
                f.write("------------------\n")
                f.write(self.analyzer.resume_text[:1000] + "...\n")
                
            messagebox.showinfo("Success", f"Analysis results saved to {file_path}")
            
        except Exception as e:
            messagebox.showerror("Error", f"Failed to save results: {str(e)}")
            
    def export_job_results(self):
        """Export job matching results to a file"""
        if not self.analyzer.matching_keywords and not self.analyzer.missing_keywords:
            messagebox.showwarning("Warning", "No job comparison has been performed yet.")
            return
            
        file_path = filedialog.asksaveasfilename(
            title="Save Comparison Results",
            defaultextension=".txt",
            filetypes=[("Text files", "*.txt"), ("CSV files", "*.csv"), ("All files", "*.*")]
        )
        
        if not file_path:
            return
            
        try:
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write("RESUME-JOB MATCHING RESULTS\n")
                f.write("===========================\n\n")
                
                # Calculate match percentage
                total_keywords = len(self.analyzer.matching_keywords) + len(self.analyzer.missing_keywords)
                if total_keywords > 0:
                    match_pct = len(self.analyzer.matching_keywords) / total_keywords * 100
                    f.write(f"MATCH PERCENTAGE: {match_pct:.1f}%\n\n")
                
                f.write("MATCHING KEYWORDS\n")
                f.write("----------------\n")
                for word, count in self.analyzer.matching_keywords:
                    f.write(f"{word}: {count}\n")
                f.write("\n")
                
                f.write("MISSING KEYWORDS\n")
                f.write("--------------\n")
                for word, count in self.analyzer.missing_keywords:
                    f.write(f"{word}: {count}\n")
                f.write("\n")
                
                f.write("SUGGESTIONS FOR IMPROVEMENT\n")
                f.write("--------------------------\n")
                f.write("Consider adding these top missing keywords to your resume:\n")
                for word, _ in self.analyzer.missing_keywords[:5]:
                    f.write(f"- {word}\n")
                
            messagebox.showinfo("Success", f"Comparison results saved to {file_path}")
            
        except Exception as e:
            messagebox.showerror("Error", f"Failed to save results: {str(e)}")

# === Main ===

def main():
    try:
        # Check for required packages
        import matplotlib
        import sklearn
        import wordcloud
        import pandas
    except ImportError as e:
        print(f"Missing required package: {str(e)}")
        print("Please install required packages using:")
        print("pip install python-docx PyPDF2 matplotlib scikit-learn pandas wordcloud")
        import sys
        sys.exit(1)
        
    # Create and run the application
    root = Tk()
    app = ResumeAnalyzerGUI(root)
    root.mainloop()

if __name__ == "__main__":
    main()





